# import clip_vanilla
# import torch
# from torch import nn
#
# device = "cuda" if torch.cuda.is_available() else "cpu"
#
#
# # class MyClip(nn.Module):
# #     def __init__(self):
# #         super(MyClip, self).__init__()
# #         # torch.jit.load("../save/models/clip_vanilla/ViT-L-14-336px.pt")
# #
# #     def forward(self, x):
# #         model = torch.load("../save/models/clip_vanilla/ViT-L-14-336px.pt")
# #         return model(x)
#
#
#
#
# print(torch.jit.load("../save/models/clip_vanilla/ViT-L-14-336px.pt"))
#
#
# # my_clip = MyClip()
# #
# # print(my_clip)
